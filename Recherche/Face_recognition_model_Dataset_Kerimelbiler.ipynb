{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T73IbN7IwgXp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Dropout\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import joblib\n",
        "import tensorflow as tf\n",
        "from keras.regularizers import l1_l2\n",
        "from keras.regularizers import l1\n",
        "from keras.regularizers import l2\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "import sklearn.metrics as metrics\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kV5QTKUwlaa",
        "outputId": "104c49dc-250d-457a-f27a-444e7529b301"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Daset OriginalFace\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CCBZvaziyVQ_"
      },
      "outputs": [],
      "source": [
        "DATA_DIR1=\"/content/drive/My Drive/Face_recognition_project/data\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # To create rotated images in order to augment the data in the original dataset\n",
        "# #Rotation de 45°\n",
        "# import os\n",
        "# import cv2\n",
        "# import numpy as np\n",
        "\n",
        "# def rotate_image(image, angle):\n",
        "#     rows, cols = image.shape[0], image.shape[1]\n",
        "#     M = cv2.getRotationMatrix2D((cols/2,rows/2),angle,1)\n",
        "#     return cv2.warpAffine(image, M, (cols,rows))\n",
        "\n",
        "# def rotate_and_save_images(folder_path, output_folder, angle):\n",
        "#     if not os.path.exists(output_folder):\n",
        "#         os.makedirs(output_folder)\n",
        "#     for filename in os.listdir(folder_path):\n",
        "#         image = cv2.imread(os.path.join(folder_path, filename))\n",
        "#         rotated_image = rotate_image(image, angle)\n",
        "#         cv2.imwrite(os.path.join(output_folder,filename+\"rotated\"+str(angle)), rotated_image)\n",
        "        \n",
        "\n",
        "# rotate_and_save_images(f\"{DATA_DIR1}/Faces_removed_classes_28c\",f\"{DATA_DIR1}/Faces_removed_classes_28c_aug2\", 5)\n",
        "# print(\"ok\")\n",
        "# rotate_and_save_images(f\"{DATA_DIR1}/Faces_removed_classes_28c\",f\"{DATA_DIR1}/Faces_removed_classes_28c_aug2\", -5)\n",
        "# print(\"ok2\")"
      ],
      "metadata": {
        "id": "s8mwcMGD41I0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nxAlyYPz30rh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f6e18de-5a0b-4928-df73-36f27ea49537"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Andy Samberg', 'Priyanka Chopra', 'Roger Federer', 'Camila Cabello', 'Hugh Jackman', 'Virat Kohli', 'Billie Eilish', 'Dwayne Johnson', 'Vijay Deverakonda', 'Anushka Sharma', 'Alia Bhatt', 'Margot Robbie', 'Tom Cruise', 'Zac Efron', 'Courtney Cox', 'Henry Cavill', 'Elizabeth Olsen', 'Amitabh Bachchan', 'Charlize Theron', 'Alexandra Daddario', 'Ellen Degeneres', 'Jessica Alba', 'Hrithik Roshan', 'Claire Holt', 'Robert Downey Jr', 'Lisa Kudrow', 'Brad Pitt', 'Natalie Portman']\n",
            "{'Andy Samberg': 0, 'Priyanka Chopra': 1, 'Roger Federer': 2, 'Camila Cabello': 3, 'Hugh Jackman': 4, 'Virat Kohli': 5, 'Billie Eilish': 6, 'Dwayne Johnson': 7, 'Vijay Deverakonda': 8, 'Anushka Sharma': 9, 'Alia Bhatt': 10, 'Margot Robbie': 11, 'Tom Cruise': 12, 'Zac Efron': 13, 'Courtney Cox': 14, 'Henry Cavill': 15, 'Elizabeth Olsen': 16, 'Amitabh Bachchan': 17, 'Charlize Theron': 18, 'Alexandra Daddario': 19, 'Ellen Degeneres': 20, 'Jessica Alba': 21, 'Hrithik Roshan': 22, 'Claire Holt': 23, 'Robert Downey Jr': 24, 'Lisa Kudrow': 25, 'Brad Pitt': 26, 'Natalie Portman': 27}\n",
            "The number of classes is : 28\n"
          ]
        }
      ],
      "source": [
        "# to get class names from Originale_face_dataset\n",
        "img_files = os.listdir(f\"{DATA_DIR1}/Faces_removed_classes_28c_aug\")\n",
        "y_img_labels = [file_name.split(\"_\")[0] for file_name in img_files[:30]]\n",
        "unique_y_img_labels = list(set(y_img_labels))\n",
        "print(unique_y_img_labels)\n",
        "\n",
        "# Puts a number on each class name in order\n",
        "dict_labels = {}\n",
        "for elt in unique_y_img_labels:\n",
        "  dict_labels[elt] = unique_y_img_labels.index(elt)\n",
        "\n",
        "print(dict_labels)\n",
        "number_of_classes = len(dict_labels)\n",
        "print(\"The number of classes is :\", number_of_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1fUZcJxAl4v",
        "outputId": "55701196-e590-4f5b-bae8-9f029dfdf232"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2450\n"
          ]
        }
      ],
      "source": [
        "# now use the dict to construct digit labels according to each of the classes it belongs to \n",
        "# and stores it as a matrix (if i'm correct)\n",
        "# according to the number of images\n",
        "\n",
        "y_labels = np.array([dict_labels[elt] for elt in y_img_labels])\n",
        "print(len(y_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYDlXECW0ytl",
        "outputId": "049c8a32-f826-46ba-ee97-da86c3750f44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2450, 160, 160, 3)\n"
          ]
        }
      ],
      "source": [
        "# Recupère les images sous forme de matrice\n",
        "#X = np.array([np.array(Image.open(f\"{DATA_DIR1}/Faces/{file_name}\")) for file_name in img_files])\n",
        "# print(X.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Saving array\n",
        "# def save_array_to_file(array, filename):\n",
        "#     with open(filename, 'wb') as f:\n",
        "#         np.save(f, array)\n",
        "# X_saved = save_array_to_file(X, '/content/drive/My Drive/Face_recognition_project/X_array_dataset1.npy')"
      ],
      "metadata": {
        "id": "qsh3KwXn97In"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !!!!!!!!!!!!!! Utilise trop de ram       To load array from saved array_file\n",
        "def load_array_from_file(filename):\n",
        "    with open(filename, 'rb') as f:\n",
        "        array = np.load(f,allow_pickle=True)\n",
        "        f.close()\n",
        "    return array\n",
        "X_loaded_array = load_array_from_file('/content/drive/My Drive/Face_recognition_project/X_array_dataset1.npy')"
      ],
      "metadata": {
        "id": "zzKV3EC8994M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uP8t3psDPT6",
        "outputId": "f030a3dd-c782-42c2-f400-d49f781cc0a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2450,)\n",
            "(2450, 160, 160, 3)\n"
          ]
        }
      ],
      "source": [
        "print(y_labels.shape)\n",
        "print(X_loaded_array.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PhU-j0rm54MS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ab08488-3082-4056-b54d-2d00910987bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1837, 160, 160, 3)\n",
            "(613, 160, 160, 3)\n",
            "(1837,)\n",
            "(613,)\n"
          ]
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_loaded_array, y_labels, test_size=0.25, random_state=4)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# create an instance of the ImageDataGenerator class with desired augmentation parameters\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest')\n",
        "\n",
        "# create augmented batches of the training data\n",
        "\n",
        "train_generator = datagen.flow(X_train, y_train, batch_size=1837)\n",
        "X_train_aug, y_train_aug = next(train_generator)\n",
        "\n",
        "print(X_train_aug.shape)\n",
        "print(y_train_aug.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRdnikNX2tlr",
        "outputId": "93d13a29-6cb9-4ca1-8abc-009bad1b94c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1837, 160, 160, 3)\n",
            "(1837,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRQWFqq060Ms"
      },
      "source": [
        "Normalize imgs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e2JkJ2xo6ySC"
      },
      "outputs": [],
      "source": [
        "X_train = X_train_aug.astype('float16')\n",
        "X_test = X_test.astype('float16')\n",
        "\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], 160, 160, 3)\n",
        "X_test = X_test.reshape(X_test.shape[0], 160, 160, 3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from keras.applications import MobileNetV2,ResNet50,VGG16,VGG19\n",
        "from keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Dropout,GlobalAveragePooling2D,AveragePooling2D\n",
        "\n",
        "im_shape = (160, 160, 3)\n",
        "\n",
        "#VGG16  (meilleur modèle jusque la)\n",
        "pretrained_model= tf.keras.applications.VGG16(include_top=False,\n",
        "                   input_shape=im_shape,\n",
        "                   pooling='avg',classes=number_of_classes,\n",
        "                   weights='imagenet')\n",
        "\n",
        "model = Sequential()\n",
        "for each_layer in pretrained_model.layers:\n",
        "        each_layer.trainable=True\n",
        "model.add(pretrained_model)\n",
        "#model.add(Flatten())\n",
        "model.add(Dense(number_of_classes, activation='softmax'))\n",
        "\n",
        "model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=Adam(learning_rate=0.0001),\n",
        "    metrics=['accuracy'],\n",
        ")\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4q5AXBpTWp5",
        "outputId": "9b954fbe-8e3c-48af-f9d2-e68deed9674b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg16 (Functional)          (None, 512)               14714688  \n",
            "                                                                 \n",
            " dense (Dense)               (None, 28)                14364     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,729,052\n",
            "Trainable params: 14,729,052\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NsryBJATEyPL"
      },
      "outputs": [],
      "source": [
        "# im_shape = (160, 160, 3)\n",
        "\n",
        "# cnn_model = Sequential()\n",
        "# cnn_model.add(Conv2D(filters=36, kernel_size=7, activation='relu', input_shape= im_shape))\n",
        "# cnn_model.add(MaxPooling2D(pool_size=2))\n",
        "# cnn_model.add(Conv2D(filters=54, kernel_size=5, activation='relu'))\n",
        "# cnn_model.add(MaxPooling2D(pool_size=2))\n",
        "# cnn_model.add(Flatten())\n",
        "# cnn_model.add(Dense(1024, activation='relu'))\n",
        "# cnn_model.add(Dropout(0.3))\n",
        "# cnn_model.add(Dense(512, activation='relu'))\n",
        "# cnn_model.add(Dropout(0.3))\n",
        "# cnn_model.add(Dense(256, activation='relu'))\n",
        "# cnn_model.add(Dropout(0.3))\n",
        "# # 31 is the number of classes (different people)  \n",
        "# cnn_model.add(Dense(31, activation='softmax'))\n",
        "\n",
        "# cnn_model.compile(\n",
        "#     loss='sparse_categorical_crossentropy',#'categorical_crossentropy',\n",
        "#     optimizer=Adam(learning_rate=0.0001),\n",
        "#     metrics=['accuracy'],\n",
        "# )\n",
        "# cnn_model.summary()\n",
        "# cnn_model.save('/content/drive/My Drive/Face_recognition_project/my_model_22.h5')\n",
        "# saved_model2 = tf.keras.models.load_model('/content/drive/My Drive/Face_recognition_project/my_model_22.h5')\n",
        "# from google.colab import files\n",
        "# files.download('/content/drive/My Drive/Face_recognition_project/my_model_22.h5') \n",
        "# print(saved_model2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "giX5WdvLGCoC",
        "outputId": "ef3d0502-5576-4aa2-cd81-385b0f1b08b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        }
      ],
      "source": [
        "start_time = datetime.now()\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.001, mode=\"auto\", patience=1, min_lr=0.0001) # --> à mettre à 0.0001\n",
        "history=model.fit(\n",
        "                      np.array(X_train_aug), np.array(y_train_aug),\n",
        "                      batch_size=256, # --> change to 256\n",
        "                      epochs=50,\n",
        "                      validation_data= (np.array(X_test), np.array(y_test)),\n",
        "                      verbose=2,\n",
        "                      #callbacks=[reduce_lr]\n",
        "                      )\n",
        "end_time = datetime.now()\n",
        "print('Duration: {}'.format(end_time - start_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ATWDKWnIwgXu"
      },
      "outputs": [],
      "source": [
        "# Saving model\n",
        "model.save('/content/drive/My Drive/Face_recognition_project/my_model_2.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yqDwZZiDVWyR"
      },
      "outputs": [],
      "source": [
        "saved_model = tf.keras.models.load_model('/content/drive/My Drive/Face_recognition_project/my_model_2.h5')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "# files.download('/content/drive/My Drive/Face_recognition_project/my_model_2.h5')"
      ],
      "metadata": {
        "id": "LZJvxynrQSTl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pRZUHj7oUUkd"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model on the test data\n",
        "train_loss, train_acc = saved_model.evaluate(X_train, y_train)\n",
        "print('Train accuracy:', train_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IzafHNcwwgXu"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model on the test data\n",
        "test_loss, test_acc = saved_model.evaluate(X_test, y_test)\n",
        "print('Test accuracy:', test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fxyxfMHBM6eE"
      },
      "outputs": [],
      "source": [
        "yhat = saved_model.predict(X_test)\n",
        "predictions = [np.argmax(elt) for elt in yhat]\n",
        "print(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eawrzk-BmaK2"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nHeKZOQGMY6t"
      },
      "outputs": [],
      "source": [
        "my_conf_matrix = confusion_matrix(y_test, predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-3rwc8fCpbJG"
      },
      "outputs": [],
      "source": [
        "import sklearn.metrics as metrics\n",
        "import seaborn as sns\n",
        "plt.figure(1, figsize=(15,5))\n",
        "sns.heatmap(metrics.confusion_matrix(y_test, predictions))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "72875036c3ae2049f56d9fe99bf3b5374ff568cd52e65cc45644d45d9a3e70ed"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}